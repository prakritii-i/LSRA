{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f88ed93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merged failed files ‚Üí failed_lyrics_merged.csv\n",
      "üìù Total unique failed entries: 40504\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === File paths ===\n",
    "failed_files = [\n",
    "    \"failed_akipped_lyrics.csv\",\n",
    "    \"failed_lyrics.csv\",\n",
    "    \"failed_skipped_lyrics2.csv\"\n",
    "]\n",
    "merged_failed_csv = \"failed_lyrics_merged.csv\"\n",
    "\n",
    "# === Load and standardize each ===\n",
    "dfs = []\n",
    "for file in failed_files:\n",
    "    df = pd.read_csv(file)\n",
    "    # Keep only track & artist columns (drop reason, lyrics if exist)\n",
    "    df = df[['track', 'artist']]\n",
    "    dfs.append(df)\n",
    "\n",
    "# === Concatenate all ===\n",
    "merged_failed = pd.concat(dfs, ignore_index=True).drop_duplicates()\n",
    "merged_failed.to_csv(merged_failed_csv, index=False)\n",
    "\n",
    "print(f\"‚úÖ Merged failed files ‚Üí {merged_failed_csv}\")\n",
    "print(f\"üìù Total unique failed entries: {len(merged_failed)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f416080c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.drop_duplicates of                 track                     artist\n",
       "0                  #1                       Áü≥‰∫ïÂ¶•Â∏´\n",
       "1     'round midnight    anne guus teerhuis trio\n",
       "2                  07                     enigma\n",
       "3                   3               florent ghys\n",
       "4                   3  sunburned hand of the man\n",
       "...               ...                        ...\n",
       "1731     zero gravity    the transmissionary six\n",
       "1732             zero                     island\n",
       "1733             zero                     loscil\n",
       "1734             zero            t. raumschmiere\n",
       "1735         zoetrope                     keshco\n",
       "\n",
       "[1736 rows x 2 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbba032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Total unique failed entries: 40504\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === File paths ===\n",
    "merged_failed_csv = \"failed_lyrics_merged.csv\"          # already merged file\n",
    "muse_csv = \"muse_90k_final.csv\"                  # original dataset with emotion labels\n",
    "output_csv = \"failed_merged_with_emotion.csv\"    # final clean output\n",
    "\n",
    "# === Load datasets ===\n",
    "failed_df = pd.read_csv(merged_failed_csv)\n",
    "muse_df = pd.read_csv(muse_csv)\n",
    "\n",
    "# === Merge to add final_emotion from original dataset ===\n",
    "failed_with_emotion = failed_df.merge(\n",
    "    muse_df[['track', 'artist', 'final_emotion']],\n",
    "    on=['track', 'artist'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# === Drop duplicates just in case ===\n",
    "failed_with_emotion = failed_with_emotion.drop_duplicates(subset=['track', 'artist'])\n",
    "\n",
    "# === Keep only required columns ===\n",
    "failed_with_emotion = failed_with_emotion[['track', 'artist', 'final_emotion']]\n",
    "\n",
    "# === Save result ===\n",
    "failed_with_emotion.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"‚úÖ Final failed dataset with emotion saved ‚Üí {output_csv}\")\n",
    "print(f\"üìä Total rows: {len(failed_with_emotion)}\")\n",
    "print(f\"‚ö†Ô∏è Missing emotion labels: {failed_with_emotion['final_emotion'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795ac733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final failed dataset with emotion saved ‚Üí failed_merged_with_emotion.csv\n",
      "üìä Total rows: 40504\n",
      "‚ö†Ô∏è Missing emotion labels: 3414\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === File paths ===\n",
    "merged_failed_csv = \"failed_lyrics_merged.csv\"          # already merged file\n",
    "muse_csv = \"muse_final_emotion_dataset.csv\"                  # original dataset with emotion labels\n",
    "output_csv = \"failed_merged_with_emotion.csv\"    # final clean output\n",
    "\n",
    "# === Load datasets ===\n",
    "failed_df = pd.read_csv(merged_failed_csv)\n",
    "muse_df = pd.read_csv(muse_csv)\n",
    "\n",
    "# === Merge to add final_emotion from original dataset ===\n",
    "failed_with_emotion = failed_df.merge(\n",
    "    muse_df[['track', 'artist', 'final_emotion']],\n",
    "    on=['track', 'artist'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# === Drop duplicates just in case ===\n",
    "failed_with_emotion = failed_with_emotion.drop_duplicates(subset=['track', 'artist'])\n",
    "\n",
    "# === Keep only required columns ===\n",
    "failed_with_emotion = failed_with_emotion[['track', 'artist', 'final_emotion']]\n",
    "\n",
    "# === Save result ===\n",
    "failed_with_emotion.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"‚úÖ Final failed dataset with emotion saved ‚Üí {output_csv}\")\n",
    "print(f\"üìä Total rows: {len(failed_with_emotion)}\")\n",
    "print(f\"‚ö†Ô∏è Missing emotion labels: {failed_with_emotion['final_emotion'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8ed672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing emotion count: 3414\n",
      "                          track                         artist final_emotion\n",
      "0                            #1                      spambient           NaN\n",
      "1          (left a) pretty scar                  adrian sieber           NaN\n",
      "2  04 - de mende dans les mende  zeru ta lur / c√©rou ta lourre           NaN\n",
      "3                            05                     panda bear           NaN\n",
      "5                          2012                    lifeisround           NaN\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'track_clean'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_29160\\2231055172.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     17\u001b[39m muse[\u001b[33m'track_clean'\u001b[39m] = muse[\u001b[33m'track'\u001b[39m].str.strip().str.lower()\n\u001b[32m     18\u001b[39m muse[\u001b[33m'artist_clean'\u001b[39m] = muse[\u001b[33m'artist'\u001b[39m].str.strip().str.lower()\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Check how many of missing ones exist in muse after cleaning\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m missing_clean_match = missing_emotion.merge(\n\u001b[32m     22\u001b[39m     muse[[\u001b[33m'track_clean'\u001b[39m, \u001b[33m'artist_clean'\u001b[39m]],\n\u001b[32m     23\u001b[39m     on=[\u001b[33m'track_clean'\u001b[39m, \u001b[33m'artist_clean'\u001b[39m],\n\u001b[32m     24\u001b[39m     how=\u001b[33m'inner'\u001b[39m\n",
      "\u001b[32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10835\u001b[39m         validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10836\u001b[39m     ) -> DataFrame:\n\u001b[32m  10837\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.merge \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m  10838\u001b[39m \n\u001b[32m> \u001b[39m\u001b[32m10839\u001b[39m         return merge(\n\u001b[32m  10840\u001b[39m             self,\n\u001b[32m  10841\u001b[39m             right,\n\u001b[32m  10842\u001b[39m             how=how,\n",
      "\u001b[32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1306\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1307\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1308\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1309\u001b[39m                         lk = cast(Hashable, lk)\n\u001b[32m-> \u001b[39m\u001b[32m1310\u001b[39m                         left_keys.append(left._get_label_or_level_values(lk))\n\u001b[32m   1311\u001b[39m                         join_names.append(lk)\n\u001b[32m   1312\u001b[39m                     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1313\u001b[39m                         \u001b[38;5;66;03m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'track_clean'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "failed = pd.read_csv(\"failed_merged_with_emotion.csv\")\n",
    "muse = pd.read_csv(\"muse_final_emotion_dataset.csv\")  # original\n",
    "\n",
    "# Identify rows with missing emotion\n",
    "missing_emotion = failed[failed['final_emotion'].isna()]\n",
    "print(\"Missing emotion count:\", len(missing_emotion))\n",
    "\n",
    "# Check sample mismatches\n",
    "print(missing_emotion.head())\n",
    "\n",
    "# See if stripping spaces helps match more\n",
    "failed['track_clean'] = failed['track'].str.strip().str.lower()\n",
    "failed['artist_clean'] = failed['artist'].str.strip().str.lower()\n",
    "muse['track_clean'] = muse['track'].str.strip().str.lower()\n",
    "muse['artist_clean'] = muse['artist'].str.strip().str.lower()\n",
    "\n",
    "# Check how many of missing ones exist in muse after cleaning\n",
    "missing_clean_match = missing_emotion.merge(\n",
    "    muse[['track_clean', 'artist_clean']],\n",
    "    on=['track_clean', 'artist_clean'],\n",
    "    how='inner'\n",
    ")\n",
    "print(\"After cleaning, matches found:\", len(missing_clean_match))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c3dd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total rows after merge: 40899\n",
      "‚ö†Ô∏è Still missing emotions: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load\n",
    "failed = pd.read_csv(\"failed_lyrics_merged.csv\")  # before emotion merge\n",
    "muse = pd.read_csv(\"muse_final_emotion_dataset.csv\")\n",
    "\n",
    "# Clean function for track/artist\n",
    "def clean_text(x):\n",
    "    if pd.isna(x): return \"\"\n",
    "    x = x.strip().lower()\n",
    "    x = re.sub(r'^\\d+\\s*[-‚Äì]?\\s*', '', x)   # remove leading track numbers like \"01 -\"\n",
    "    x = re.sub(r'[^\\w\\s]', '', x)           # remove punctuation\n",
    "    x = re.sub(r'\\s+', ' ', x)              # normalize spaces\n",
    "    return x\n",
    "\n",
    "# Apply cleaning\n",
    "failed['track_clean'] = failed['track'].apply(clean_text)\n",
    "failed['artist_clean'] = failed['artist'].apply(clean_text)\n",
    "muse['track_clean'] = muse['track'].apply(clean_text)\n",
    "muse['artist_clean'] = muse['artist'].apply(clean_text)\n",
    "\n",
    "# Merge on cleaned fields\n",
    "merged = failed.merge(\n",
    "    muse[['track_clean','artist_clean','final_emotion']],\n",
    "    on=['track_clean','artist_clean'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check result\n",
    "print(\"‚úÖ Total rows after merge:\", len(merged))\n",
    "print(\"‚ö†Ô∏è Still missing emotions:\", merged['final_emotion'].isna().sum())\n",
    "\n",
    "# Save\n",
    "merged.to_csv(\"failed_merged_with_emotion_cleaned.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
